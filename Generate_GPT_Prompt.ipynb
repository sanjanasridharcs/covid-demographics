{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUII+ZkkXmQYBuBDfCQs4U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjanasridharcs/covid-demographics/blob/master/Generate_GPT_Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!pip install praat-parselmouth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d4p53rTls_c",
        "outputId": "6c7df1ab-0f46-47df-b059-dbc2b699f614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from praat-parselmouth) (1.25.2)\n",
            "Installing collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup stuff + definitions\n",
        "\n",
        "# acoustic parameters\n",
        "import parselmouth\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def analyze_wav_file(file_path):\n",
        "    # Load the WAV file\n",
        "    sound = parselmouth.Sound(file_path)\n",
        "\n",
        "    # Analyze pitch\n",
        "    F0 = sound.to_pitch()\n",
        "    F0_values = F0.selected_array['frequency']\n",
        "    F0_average = np.average(F0_values)\n",
        "    F0_max = np.max(F0_values)\n",
        "    F0_min = F0_values[0]\n",
        "    for x in F0_values:\n",
        "      if (x < F0_min):\n",
        "        if (x != 0):\n",
        "          F0_min = x\n",
        "    F0_variability = 0\n",
        "    for x in F0_values:\n",
        "      F0_variability += (x - F0_average) ** 2\n",
        "    F0_variability /= len(F0_values)\n",
        "    F0_variability = F0_variability ** (1/2)\n",
        "\n",
        "    # Analyze intensity\n",
        "    intensity = sound.to_intensity()\n",
        "    intensity_values = intensity.values.T\n",
        "    intensity_max = np.max(intensity_values)\n",
        "    intensity_variability = 0;\n",
        "    for x in intensity_values:\n",
        "      intensity_variability += (x - np.average(intensity_values)) ** 2\n",
        "    intensity_variability /= len(intensity_values)\n",
        "    intensity_variability = intensity_variability ** (1/2)\n",
        "    intensity_min = np.min(intensity_values)\n",
        "\n",
        "    #Analyze % silence\n",
        "    percent_silence = 0\n",
        "    for x in intensity_values:\n",
        "      if x < 45:\n",
        "        percent_silence += 1\n",
        "    percent_silence /= len(intensity_values)\n",
        "    percent_silence *= 100\n",
        "\n",
        "    return {\n",
        "       \"F0_average\": F0_average,\n",
        "       \"F0_variability\": F0_variability,\n",
        "       \"F0_max\": F0_max,\n",
        "       \"F0_min\": F0_min,\n",
        "       \"intensity_variability\": intensity_variability,\n",
        "       \"intensity_max\": intensity_max,\n",
        "       \"intensity_min\": intensity_min,\n",
        "       \"% silence\": percent_silence\n",
        "    }\n",
        "\n",
        "# CREMA-D SNN model\n",
        "print(\"downloading CREMA D SNN model\")\n",
        "!gdown 12UGtFKxLara0JoOsY9_VLWumbZd_hYnW\n",
        "\n",
        "# Anxiety SNN model\n",
        "print(\"downloading anxiety SNN model\")\n",
        "!gdown 1kOAlxmRpZB63P22LIzcP4_GvPUlmzDWg\n",
        "\n",
        "# SNN model\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc2(x)\n",
        "        s = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Load the models\n",
        "with open(\"EmotionPredictionModel.pkl\", 'rb') as f1:\n",
        "  cremad_snn_model = pickle.load(f1)\n",
        "\n",
        "with open(\"AnxietyPredictionModel.pkl\", 'rb') as f2:\n",
        "  anxiety_snn_model = pickle.load(f2)\n",
        "\n",
        "# functions for CREMA-D\n",
        "def wav_to_embedding(file_path, n_mfcc=13):\n",
        "  y, sr = librosa.load(file_path)\n",
        "\n",
        "  # Extract MFCC features\n",
        "  mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "  # Normalize the MFCCs\n",
        "  mfccs_normalized = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "  return mfccs_normalized\n",
        "\n",
        "def predict_CREMAD_SNN_sentiment(file_path):\n",
        "  embedding = wav_to_embedding(file_path)\n",
        "  embedding_tensor = torch.tensor(embedding, dtype=torch.float32)\n",
        "\n",
        "  # Pass the embedding through your trained model\n",
        "  cremad_snn_model.eval()  # Set the model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "      output = cremad_snn_model(embedding_tensor.unsqueeze(0))\n",
        "\n",
        "  probabilities = F.softmax(output, dim=1)[0]\n",
        "\n",
        "  # Round each value to two decimal places\n",
        "  rounded_values = np.round(probabilities.numpy() * 100, 2)\n",
        "\n",
        "  return rounded_values\n",
        "\n",
        "def predict_anxiety_SNN_sentiment(file_path):\n",
        "  embedding = wav_to_embedding(file_path)\n",
        "  embedding_tensor = torch.tensor(embedding, dtype=torch.float32)\n",
        "\n",
        "  # Pass the embedding through your trained model\n",
        "  anxiety_snn_model.eval()  # Set the model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "      output = anxiety_snn_model(embedding_tensor.unsqueeze(0))\n",
        "\n",
        "  probabilities = F.softmax(output, dim=1)[0]\n",
        "\n",
        "  # Round each value to two decimal places\n",
        "  rounded_values = np.round(probabilities.numpy() * 100, 2)\n",
        "\n",
        "  return rounded_values\n",
        "\n",
        "\n",
        "# CREMA-D CNN model\n",
        "!gdown 1kmBX3qh9Ndzx81Mbp5zbLeaSEXnECHAE\n",
        "\n",
        "# Anxiety CNN model\n",
        "!gdown 1UrAvKQHndFNiaVDlAtAfPO24W9AU6kYp\n",
        "\n",
        "\n",
        "# Function to pad width with silent space (zeroes)\n",
        "def equalize_width(spectrogram, target_width):\n",
        "    current_width = spectrogram.shape[1]\n",
        "    if current_width < target_width:\n",
        "        # If the current width is smaller, pad the spectrogram\n",
        "        padding = np.zeros((spectrogram.shape[0], target_width - current_width))\n",
        "        equalized_spectrogram = np.hstack((spectrogram, padding))\n",
        "    elif current_width > target_width:\n",
        "        # If the current width is larger, trim the spectrogram\n",
        "        equalized_spectrogram = spectrogram[:, :target_width]\n",
        "    else:\n",
        "        # If the width is already equal, return the original spectrogram\n",
        "        equalized_spectrogram = spectrogram\n",
        "    return equalized_spectrogram\n",
        "\n",
        "num_classes = 6\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_channels, height, width):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # Define your convolutional layers here\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Add more conv layers if needed\n",
        "        )\n",
        "        # Add more layers as necessary\n",
        "\n",
        "        # Pass a dummy tensor through the conv layers to get the output size\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros((1, input_channels, height, width))\n",
        "            dummy_output = self.conv_layers(dummy_input)\n",
        "            flattened_size = int(np.prod(dummy_output.size()[1:]))\n",
        "aww\n",
        "        # Define the fully connected layers using the correct flattened size\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(flattened_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "            # Add more fc layers if needed\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layers\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "# Load the models\n",
        "with open(\"EmotionPredictionModelCNN.pkl\", 'rb') as f3:\n",
        "  cremad_cnn_model = pickle.load(f3)\n",
        "\n",
        "with open(\"AnxietyPredictionModelCNN.pkl\", 'rb') as f4:\n",
        "  anxiety_cnn_model = pickle.load(f4)\n",
        "\n",
        "def predict_CREMAD_CNN_sentiment(filepath):\n",
        "  y, sr = librosa.load(filepath)\n",
        "  S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "  S_DB = librosa.power_to_db(S, ref=np.max)\n",
        "  S_DB = equalize_width(S_DB, 174)\n",
        "\n",
        "  # Ensure the output shape is (1, C, H, W)\n",
        "  S_DB = np.expand_dims(S_DB, axis=0)  # Add a channel dimension\n",
        "  S_DB = np.expand_dims(S_DB, axis=0)  # Add a batch size dimension\n",
        "  input = torch.tensor(S_DB, dtype=torch.float32)\n",
        "\n",
        "  cremad_cnn_model.eval()\n",
        "  with torch.no_grad():\n",
        "    prediction = cremad_cnn_model(input)\n",
        "    prediction_index = torch.argmax(prediction, dim=1)\n",
        "\n",
        "  emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\"]\n",
        "  predicted_emotion = emotions[prediction_index.item()]\n",
        "  return predicted_emotion\n",
        "\n",
        "def predict_anxiety_CNN_sentiment(filepath):\n",
        "  y, sr = librosa.load(filepath)\n",
        "  S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "  S_DB = librosa.power_to_db(S, ref=np.max)\n",
        "  S_DB = equalize_width(S_DB, 174)\n",
        "\n",
        "  # Ensure the output shape is (1, C, H, W)\n",
        "  S_DB = np.expand_dims(S_DB, axis=0)  # Add a channel dimension\n",
        "  S_DB = np.expand_dims(S_DB, axis=0)  # Add a batch size dimension\n",
        "  input = torch.tensor(S_DB, dtype=torch.float32)\n",
        "\n",
        "  anxiety_cnn_model.eval()\n",
        "  with torch.no_grad():\n",
        "    prediction = anxiety_cnn_model(input)\n",
        "    prediction_index = torch.argmax(prediction, dim=1)\n",
        "\n",
        "  print(prediction)\n",
        "\n",
        "  emotions = ['Angry', 'Anxious', 'Apologetic', 'Assertive', 'Concerned', 'Encouraging', 'Excited', 'Happy', 'Neutral', 'Sad']\n",
        "  predicted_emotion = emotions[prediction_index.item()]\n",
        "  return predicted_emotion\n",
        "\n",
        "\n",
        "def print_cremad(prediction):\n",
        "  labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\"]\n",
        "  for i, label in enumerate(labels):\n",
        "    print(label + \": \" + str(prediction[i]) + \"%\")\n",
        "\n",
        "def print_anxiety(prediction):\n",
        "  labels = ['Angry', 'Anxious', 'Apologetic', 'Assertive', 'Concerned', 'Encouraging', 'Excited', 'Happy', 'Neutral', 'Sad']\n",
        "  for i, label in enumerate(labels):\n",
        "    print(label + \": \" + str(prediction[i]) + \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "yCcEUlM9majj",
        "outputId": "6d27dcb1-4010-4905-bce1-779bc523fce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading CREMA D SNN model\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12UGtFKxLara0JoOsY9_VLWumbZd_hYnW\n",
            "To: /content/EmotionPredictionModel.pkl\n",
            "100% 3.32k/3.32k [00:00<00:00, 17.1MB/s]\n",
            "downloading anxiety SNN model\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kOAlxmRpZB63P22LIzcP4_GvPUlmzDWg\n",
            "To: /content/AnxietyPredictionModel.pkl\n",
            "100% 3.50k/3.50k [00:00<00:00, 14.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kmBX3qh9Ndzx81Mbp5zbLeaSEXnECHAE\n",
            "To: /content/EmotionPredictionModelCNN.pkl\n",
            "100% 91.2M/91.2M [00:00<00:00, 151MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UrAvKQHndFNiaVDlAtAfPO24W9AU6kYp\n",
            "To: /content/AnxietyPredictionModelCNN_old.pkl\n",
            "100% 91.2M/91.2M [00:01<00:00, 80.2MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'AnxietyPredictionModelCNN.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-79ab4e013573>\u001b[0m in \u001b[0;36m<cell line: 199>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0mcremad_cnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AnxietyPredictionModelCNN.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m   \u001b[0manxiety_cnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AnxietyPredictionModelCNN.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsnFysLmlXBJ",
        "outputId": "88381556-0d38-4012-e0c9-abf348273e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0809, 0.0485, 0.0965, 0.1140, 0.0500, 0.0938, 0.0685, 0.0616, 0.0792,\n",
            "         0.0712]])\n",
            "Please generate an anxiety score for a wav file with the following parameters:\n",
            "\n",
            "The acoustic parameters are:\n",
            "{'F0_average': 89.84463727530301, 'F0_variability': 89.88775892216091, 'F0_max': 193.6008804646606, 'F0_min': 0.0, 'intensity_variability': array([13.73089022]), 'intensity_max': 75.18166924003457, 'intensity_min': 33.17294339227881, '% silence': 29.72972972972973}\n",
            "\n",
            "The emotion breakdown by percentage from a simple neural network model for the CREMA-D dataset is:\n",
            "Angry: 1.01%\n",
            "Disgust: 0.0%\n",
            "Fear: 96.68%\n",
            "Happy: 2.31%\n",
            "Sad: 0.0%\n",
            "Surprise: 0.0%\n",
            "\n",
            "The emotion breakdown by percentage from a simple neural network model for the JL-corpus dataset is:\n",
            "Angry: 49.82%\n",
            "Anxious: 5.12%\n",
            "Apologetic: 0.0%\n",
            "Assertive: 0.0%\n",
            "Concerned: 2.93%\n",
            "Encouraging: 0.01%\n",
            "Excited: 41.95%\n",
            "Happy: 0.17%\n",
            "Neutral: 0.0%\n",
            "Sad: 0.0%\n",
            "\n",
            "The emotion prediction from a convolutional neural network model for the CREMA-D dataset is:\n",
            "Sad\n",
            "\n",
            "The emotion breakdown by percentage from a convolutional neural network model for the JL-corpus dataset is:\n",
            "Assertive\n"
          ]
        }
      ],
      "source": [
        "# ACTION: upload m4a file into Colab as \"recording.m4a\"\n",
        "\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# convert m4a to wav\n",
        "m4a_file = 'sample.m4a'\n",
        "wav_file = 'input.wav'\n",
        "\n",
        "audio = AudioSegment.from_file(m4a_file, format=\"m4a\")\n",
        "audio.export(wav_file, format=\"wav\")\n",
        "\n",
        "# get acoustic parameters\n",
        "acoustic_params = analyze_wav_file(\"input.wav\")\n",
        "\n",
        "# get emotion prediction via CREMA-D sentiment SNN\n",
        "crema_sentiment_snn = predict_CREMAD_SNN_sentiment(\"input.wav\")\n",
        "\n",
        "# get emotion prediction via CREMA-D sentiment CNN\n",
        "crema_sentiment_cnn = predict_CREMAD_CNN_sentiment(\"input.wav\")\n",
        "\n",
        "# get emotion prediction via anxiety sentiment SNN\n",
        "anxiety_sentiment_snn = predict_anxiety_SNN_sentiment(\"input.wav\")\n",
        "\n",
        "# get emotion prediction via anxiety sentiment CNN\n",
        "anxiety_sentiment_cnn = predict_anxiety_CNN_sentiment(\"input.wav\")\n",
        "\n",
        "# print GPT prompt\n",
        "print(\"Please generate an anxiety score for a wav file with the following parameters:\")\n",
        "print()\n",
        "print(\"The acoustic parameters are:\")\n",
        "print(acoustic_params)\n",
        "print()\n",
        "print(\"The emotion breakdown by percentage from a simple neural network model for the CREMA-D dataset is:\")\n",
        "print_cremad(crema_sentiment_snn)\n",
        "print()\n",
        "print(\"The emotion breakdown by percentage from a simple neural network model for the JL-corpus dataset is:\")\n",
        "print_anxiety(anxiety_sentiment_snn)\n",
        "print()\n",
        "print(\"The emotion prediction from a convolutional neural network model for the CREMA-D dataset is:\")\n",
        "print(crema_sentiment_cnn)\n",
        "print()\n",
        "print(\"The emotion breakdown by percentage from a convolutional neural network model for the JL-corpus dataset is:\")\n",
        "print(anxiety_sentiment_cnn)"
      ]
    }
  ]
}